package main

import (
	"bufio"
	"bytes"
	"context"
	"flag"
	"fmt"
	"log"
	"os"
	"os/exec"
	"runtime"
	"strings"
	"time"

	"github.com/briandowns/spinner"
	"github.com/fatih/color"
	openai "github.com/sashabaranov/go-openai"
)

var (
	// Command line flags.
	writeFile   bool
	showVersion bool
	useModel    Model

	// Updated during release process with -ldflags=-X=main.version.
	version = "dev"
)

var client = openai.NewClient(os.Getenv("OPENAI_API_KEY"))

func init() {
	flag.BoolVar(&writeFile, "w", false, "write shell script to input file. This will overwrite the input file.")
	flag.BoolVar(&showVersion, "v", false, "print version number and exit")
	flag.Var(&useModel, "m", fmt.Sprintf("specify the model to use (%s)", strings.Join(validModels(), " or ")))

	flag.Usage = usage
}

func usage() {
	fmt.Fprintf(os.Stderr, "Usage: %s [OPTIONS] FILE\n\n", os.Args[0])
	fmt.Fprintf(os.Stderr, "Execute shellcheck on the given script and pass the results to a large language model "+
		"for making appropriate corrections.\n")
	fmt.Fprintf(os.Stderr, "The default behavior displays the modified script in the console. Use the '-w' flag "+
		"to save the changes directly to the specified file.\n")
	fmt.Fprintf(os.Stderr, "The shellcheck binary must be present in your path.\n\n")
	fmt.Fprintln(os.Stderr, "OPTIONS:")
	flag.PrintDefaults()
	fmt.Fprintln(os.Stderr, "")
	fmt.Fprintln(os.Stderr, "ENVIRONMENT:")
	fmt.Fprintln(os.Stderr, "  OPENAI_API_KEY OpenAI API key")
}

func printf(format string, a ...interface{}) {
	_, _ = fmt.Fprintf(color.Output, format, a...)
}

func main() {
	flag.Parse()

	if showVersion {
		fmt.Fprintf(os.Stderr, "%s %s (runtime: %s)\n", os.Args[0], version, runtime.Version())
		os.Exit(0)
	}

	args := flag.Args()
	if len(args) != 1 {
		flag.Usage()
		os.Exit(1)
	}

	filePath := args[0]

	run(filePath)
}

func run(filePath string) {
	analysis, err := execShellCheck(filePath)
	if err != nil {
		log.Fatal(err)
	}

	if analysis == "" {
		printf("%s\n", color.GreenString("No issues have been detected by shellcheck."))
		return
	}

	printf("%s\n", color.YellowString("The following issues have been detected by shellcheck:"))
	printf("%s\n", color.CyanString(analysis))

	if !getUserConfirmation() {
		printf("%s\n", "Aborting.")
		return
	}

	script, err := os.ReadFile(filePath)
	if err != nil {
		log.Fatalf("unable to read file: %v", err)
	}

	result, err := getChatCompletion(string(script), analysis)
	if err != nil {
		log.Fatalf("error calling completion API: %v", err)
	}

	if writeFile {
		if err := os.WriteFile(filePath, []byte(result), 0600); err != nil {
			log.Fatalf("could not write updated script to file: %v", err)
		}

		printf("\n%s %s\n", color.GreenString("Updated script written to"), color.GreenString(filePath))
	} else {
		printf("\n%s\n", color.GreenString("Contents of updated script:"))
		printf("\n%s\n\n", result)
	}

	printf("%s\n\n", color.YellowString("CAUTION: This script was generated by a language model and "+
		"may contain errors or nonsensical content. Please review thoroughly before committing."))
}

func execShellCheck(filePath string) (string, error) {
	cmd := exec.Command("shellcheck", filePath)

	output, err := cmd.CombinedOutput()
	if err != nil {
		exitCode := cmd.ProcessState.ExitCode()
		// shellcheck returns exit code 1 when it finds issues
		if exitCode != 1 {
			return "", fmt.Errorf("shellcheck exited with code %d: %w", exitCode, err)
		}

		return string(output), nil
	}

	return "", nil
}

func getUserConfirmation() bool {
	printf("%s", color.YellowString("Would you like the LLM to proceed with correction of issues (y/N)? "))

	reader := bufio.NewReader(os.Stdin)

	for {
		input, err := reader.ReadString('\n')
		if err != nil {
			log.Fatalf("error reading user confirmation: %v", err)
		}

		input = strings.ToLower(strings.TrimSpace(input))

		switch input {
		case "y", "yes":
			return true
		case "n", "no":
			return false
		default:
			printf("%s", color.RedString("Invalid input. Please enter 'y' or 'n': "))
		}
	}
}

func getChatCompletion(script, analysis string) (string, error) {
	spin := spinner.New(spinner.CharSets[26], 250*time.Millisecond)
	spin.Prefix = "Waiting for response from chat completion API"

	spin.Start()
	defer spin.Stop()

	data := map[string]string{
		"ScriptContents":       script,
		"StaticAnalysisOutput": analysis,
	}

	var buffer bytes.Buffer
	if err := userPromptTmpl.Execute(&buffer, data); err != nil {
		return "", fmt.Errorf("unable to format prompt: %w", err)
	}

	resp, err := client.CreateChatCompletion(
		context.Background(),
		buildCompletionRequest(buffer.String()),
	)
	if err != nil {
		return "", fmt.Errorf("could not create chat completion: %w", err)
	}

	if len(resp.Choices) == 0 {
		return "", fmt.Errorf("empty response")
	}

	return resp.Choices[0].Message.Content, nil
}

func buildCompletionRequest(prompt string) openai.ChatCompletionRequest {
	var model string

	switch useModel {
	case GPT35Turbo:
		model = openai.GPT3Dot5Turbo
	case GPT4Turbo:
		model = openai.GPT4TurboPreview
	default:
		model = openai.GPT3Dot5Turbo
	}

	return openai.ChatCompletionRequest{
		Model: model,
		Messages: []openai.ChatCompletionMessage{
			{
				Role:    openai.ChatMessageRoleSystem,
				Content: systemPrompt,
			},
			{
				Role:    openai.ChatMessageRoleUser,
				Content: prompt,
			},
		},
	}
}
